{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import (\n",
    "    ToTensor,\n",
    "    RandomHorizontalFlip,\n",
    "    Compose,\n",
    "    RandomResizedCrop,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "> CIFAR10, 100전용 padding 4 pixel 및 random 32*32 crop하는 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Submean(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        return None\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        # Subtract the mean from each pixel along each channel\n",
    "        _mean = tensor.mean(axis=(1, 2))\n",
    "        tensor = tensor - _mean[:, None, None]\n",
    "\n",
    "        return tensor\n",
    "\n",
    "class CustomRandomResizedCrop(RandomResizedCrop):\n",
    "    def __call__(self, img):\n",
    "        # Add padding to the image\n",
    "        img = F.pad(img, (4, 4, 4, 4), mode=\"constant\", value=0)\n",
    "        return super().__call__(img)\n",
    "\n",
    "class LoadDataset:\n",
    "    def __init__(self, root, seceted_dataset=\"CIFAR100\"):\n",
    "        \n",
    "        self.dataset_name = seceted_dataset\n",
    "        dataset_mapping = {\n",
    "            \"CIFAR100\": datasets.CIFAR100,\n",
    "            \"CIFAR10\": datasets.CIFAR10,\n",
    "            # Add more datasets if needed\n",
    "        }\n",
    "        \n",
    "        default_transforms = Compose([ToTensor(), Submean()])\n",
    "\n",
    "        if self.dataset_name in dataset_mapping:\n",
    "            ref_train = dataset_mapping[self.dataset_name](\n",
    "                root=root,\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=default_transforms,\n",
    "            )\n",
    "            self.testing_data = dataset_mapping[self.dataset_name](\n",
    "                root=root,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=default_transforms,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dataset: {self.dataset_name}\")\n",
    "\n",
    "        # Split to train and valid set\n",
    "        total_length = len(ref_train)\n",
    "        train_length = int(total_length * 0.9)\n",
    "        valid_length = total_length - train_length\n",
    "        splited_train, self.valid_data = random_split(\n",
    "            ref_train, [train_length, valid_length]\n",
    "        )\n",
    "\n",
    "        # Apply transform at each dataset\n",
    "        self.train_data = splited_train\n",
    "        self.train_data.transform = copy.deepcopy(default_transforms)\n",
    "        ### 여기 transforms도 주소 레퍼런스따는거라 deep copy한 다음에 append해야함.\n",
    "        self.train_data.transform.transforms.append(RandomHorizontalFlip(p=0.5))\n",
    "        self.train_data.transform.transforms.append(CustomRandomResizedCrop([32, 32]))\n",
    "        self.valid_data.transform = default_transforms\n",
    "        \"\"\"\n",
    "        random crop : https://arxiv.org/pdf/1409.5185.pdf\n",
    "        we also augmented the dataset by zero padding 4 pixels on each side, then do corner cropping and random flipping on\n",
    "        the fly during training. No model averaging is done at the test phase and we only crop the center of a test sample\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Copy classes data\n",
    "        self.train_data.classes = ref_train.classes\n",
    "        self.valid_data.classes = ref_train.classes\n",
    "\n",
    "        self.train_data.class_to_idx = ref_train.class_to_idx\n",
    "        self.valid_data.class_to_idx = ref_train.class_to_idx\n",
    "\n",
    "        return\n",
    "\n",
    "    def unpack(self):\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"Dataset : \", self.dataset_name)\n",
    "        print(\"- Length of Train Set : \", len(self.train_data))\n",
    "        print(\"- Length of Valid Set : \", len(self.valid_data))\n",
    "        print(\"- Length of Test Set : \", len(self.testing_data))\n",
    "        print(\"- Count of Classes : \", len(self.train_data.classes))\n",
    "\n",
    "        return (\n",
    "            self.train_data,\n",
    "            self.valid_data,\n",
    "            self.testing_data,\n",
    "            len(self.train_data.classes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that the dataset is loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 256\n",
    "DATASET = \"CIFAR10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------\n",
      "Dataset :  CIFAR10\n",
      "- Length of Train Set :  45000\n",
      "- Length of Valid Set :  5000\n",
      "- Length of Test Set :  10000\n",
      "- Count of Classes :  10\n"
     ]
    }
   ],
   "source": [
    "_dataset = LoadDataset(root=\"data\", seceted_dataset=DATASET)\n",
    "train_data, valid_data, test_data, COUNT_OF_CLASSES = _dataset.unpack()\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=BATCH, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Submean()\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    CustomRandomResizedCrop(size=[32, 32], scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    ToTensor()\n",
      "    Submean()\n",
      ")\n",
      "Compose(\n",
      "    ToTensor()\n",
      "    Submean()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(train_data.transform)\n",
    "print(valid_data.transform)\n",
    "print(test_data.transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 3, 32, 32])\n",
      "mean of X tensor([-3.1168e-09, -3.0930e-09, -2.1206e-09])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(\"mean of X\", X.mean(dim=(0, 2, 3)))\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the class names\n",
    "class_names = test_dataloader.dataset.classes\n",
    "count = 0\n",
    "\n",
    "# Create a subplot with 2 rows and 5 columns\n",
    "fig, axs = plt.subplots(2, 5, figsize=(8, 4))\n",
    "\n",
    "# Iterate over the first batch of images and labels\n",
    "for images, labels in test_dataloader:\n",
    "    # Convert the images to numpy arrays\n",
    "    images = images.numpy()\n",
    "    \n",
    "    # Iterate over the images and labels\n",
    "    for i in range(len(images)):\n",
    "        # Get the image and label\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        # Convert the image from tensor to numpy array\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        \n",
    "        # Plot the image in the appropriate subplot\n",
    "        ax = axs[count // 5, count % 5]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f\"{class_names[label], label}\")\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Increment the count\n",
    "        count += 1\n",
    "        \n",
    "        # Break the loop if we have displayed 10 images\n",
    "        if count == 10:\n",
    "            break\n",
    "            \n",
    "    # Break the loop if we have displayed 10 images\n",
    "    if count == 10:\n",
    "        break\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaplemant The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inputs, outputs, _Downsample=False):\n",
    "        super().__init__()\n",
    "        self._Downsample = _Downsample\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inputs, outputs, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(outputs, eps=1e-05, momentum=0.1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(outputs, outputs, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(outputs, eps=1e-05, momentum=0.1)\n",
    "\n",
    "        if self._Downsample == True:\n",
    "            self.conv1.stride = 2\n",
    "\n",
    "            self.conv_down = nn.Conv2d(\n",
    "                inputs, outputs, kernel_size=1, stride=2, bias=False\n",
    "            )\n",
    "            # In paper, downsampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "            # 이거 토치 공식 resnet에서도 배치까지 있는 4차원이라 conv2d로 함.\n",
    "            # 여기 BN빼니까 완전히 망가져버림. acc 10% 찍힘.\n",
    "            nn.init.kaiming_normal_(\n",
    "                self.conv_down.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "            )\n",
    "            self.bn_down = nn.BatchNorm2d(\n",
    "                outputs, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        https://pytorch.org/docs/stable/_modules/torch/nn/init.html#kaiming_normal_\n",
    "        \"\"\"\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x1(identity) :\", x.shape, \"Downsample :\", self._Downsample)\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # print(\"x2 :\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self._Downsample == True:\n",
    "            identity = self.conv_down(identity)\n",
    "            identity = self.bn_down(identity)\n",
    "            # print(\"x3(downsampled) :\", identity.shape)\n",
    "        # print(\"x4 :\", identity.shape)\n",
    "        x = x + identity  # 여기 x+=identity로 하면 안 됨. inplace operation이라서.\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyResNet34(nn.Module):\n",
    "    def __init__(self, _BlockClass=Block, _num_classes=1000):\n",
    "        super().__init__()\n",
    "        self._num_classes = _num_classes\n",
    "\n",
    "        # 1. input layer\n",
    "        # input : 224x224x3        # output : 112x112x64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 2. 64ch 3x3 conv x 3\n",
    "        # input : 112x112x64        # output : 56x56x64\n",
    "        self.conv64blocks = nn.Sequential(\n",
    "            _BlockClass(64, 64), _BlockClass(64, 64), _BlockClass(64, 64)\n",
    "        )\n",
    "\n",
    "        # 3. 128ch 3x3 conv x 4\n",
    "        # input : 56x56x64        # output : 28x28x128\n",
    "        self.conv128blocks = nn.Sequential(\n",
    "            _BlockClass(64, 128, _Downsample=True),\n",
    "            _BlockClass(128, 128),\n",
    "            _BlockClass(128, 128),\n",
    "            _BlockClass(128, 128),\n",
    "        )\n",
    "\n",
    "        # 4. 256ch 3x3 conv x 6\n",
    "        # input : 28x28x128        # output : 14x14x256\n",
    "        self.conv256blocks = nn.Sequential(\n",
    "            _BlockClass(128, 256, _Downsample=True),\n",
    "            _BlockClass(256, 256),\n",
    "            _BlockClass(256, 256),\n",
    "            _BlockClass(256, 256),\n",
    "            _BlockClass(256, 256),\n",
    "            _BlockClass(256, 256),\n",
    "        )\n",
    "\n",
    "        # 5. 512ch 3x3 conv x 3\n",
    "        # input : 14x14x256        # output : 7x7x512\n",
    "        self.conv512blocks = nn.Sequential(\n",
    "            _BlockClass(256, 512, _Downsample=True),\n",
    "            _BlockClass(512, 512),\n",
    "            _BlockClass(512, 512),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 7x7x512 -> 1x1x512 ?????\n",
    "        self.fc1 = nn.Linear(in_features=512, out_features=self._num_classes, bias=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv64blocks(x)\n",
    "\n",
    "        x = self.conv128blocks(x)\n",
    "\n",
    "        x = self.conv256blocks(x)\n",
    "\n",
    "        x = self.conv512blocks(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용할 CPU나 GPU, MPS 장치를 얻습니다.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyResNet34(Block, COUNT_OF_CLASSES).to(device)\n",
    "# model.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fvcore.nn import FlopCountAnalysis\n",
    "# from fvcore.nn import flop_count_table\n",
    "\n",
    "# tmp_input = torch.rand(2, 3, 32, 32).to(device)\n",
    "# flops = FlopCountAnalysis(model, tmp_input)\n",
    "# print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total parameters: 21.29M\n"
     ]
    }
   ],
   "source": [
    "# How many have params?\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of total parameters: {total_params/1e6:2.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 및 손실 함수, 최적화기 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nReduceLROnPlateau 스케줄러는 mode='min'으로 설정되어 손실이 감소해야 학습률을 조절합니다. \\npatience는 얼마나 기다렸다가 학습률을 조절할지를 결정하며, \\nfactor는 학습률을 조절할 때 사용할 인수입니다. \\n>> now learning의 0.1로 조정 >> divide by 10\\nverbose=True로 설정하면 언제 학습률이 조절되었는지 출력됩니다.\\n\\nhttps://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", patience=30, factor=0.1, verbose=True, threshold=1e-4\n",
    ")\n",
    "\"\"\"\n",
    "ReduceLROnPlateau 스케줄러는 mode='min'으로 설정되어 손실이 감소해야 학습률을 조절합니다. \n",
    "patience는 얼마나 기다렸다가 학습률을 조절할지를 결정하며, \n",
    "factor는 학습률을 조절할 때 사용할 인수입니다. \n",
    ">> now learning의 0.1로 조정 >> divide by 10\n",
    "verbose=True로 설정하면 언제 학습률이 조절되었는지 출력됩니다.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "\"\"\"\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 11.04 seconds\n",
      "Train Loss: 4.4232 | Train Acc: 13.09%\n",
      "Valid Loss: 2.2711 | Valid Acc: 17.28%\n",
      "Test Loss: 2.3297 | Test Acc: 17.06%\n",
      "--------------------------------------------------\n",
      "Epoch 2/5000:\n",
      "Training time: 10.13 seconds\n",
      "Train Loss: 2.2917 | Train Acc: 19.29%\n",
      "Valid Loss: 2.6483 | Valid Acc: 13.14%\n",
      "Test Loss: 2.6844 | Test Acc: 13.27%\n",
      "--------------------------------------------------\n",
      "Epoch 3/5000:\n",
      "Training time: 10.13 seconds\n",
      "Train Loss: 2.0940 | Train Acc: 23.72%\n",
      "Valid Loss: 1.9607 | Valid Acc: 28.88%\n",
      "Test Loss: 1.9760 | Test Acc: 27.66%\n",
      "--------------------------------------------------\n",
      "Epoch 4/5000:\n",
      "Training time: 10.15 seconds\n",
      "Train Loss: 1.9011 | Train Acc: 29.72%\n",
      "Valid Loss: 1.8955 | Valid Acc: 31.26%\n",
      "Test Loss: 1.9172 | Test Acc: 31.16%\n",
      "--------------------------------------------------\n",
      "Epoch 5/5000:\n",
      "Training time: 10.16 seconds\n",
      "Train Loss: 1.7762 | Train Acc: 35.08%\n",
      "Valid Loss: 1.8120 | Valid Acc: 34.00%\n",
      "Test Loss: 1.8323 | Test Acc: 34.52%\n",
      "--------------------------------------------------\n",
      "Epoch 6/5000:\n",
      "Training time: 10.18 seconds\n",
      "Train Loss: 1.6864 | Train Acc: 38.73%\n",
      "Valid Loss: 1.8226 | Valid Acc: 33.48%\n",
      "Test Loss: 1.8362 | Test Acc: 33.97%\n",
      "--------------------------------------------------\n",
      "Epoch 7/5000:\n",
      "Training time: 10.18 seconds\n",
      "Train Loss: 1.6035 | Train Acc: 42.18%\n",
      "Valid Loss: 2.0395 | Valid Acc: 28.88%\n",
      "Test Loss: 2.0456 | Test Acc: 28.56%\n",
      "--------------------------------------------------\n",
      "Epoch 8/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 1.5461 | Train Acc: 44.26%\n",
      "Valid Loss: 1.6209 | Valid Acc: 42.46%\n",
      "Test Loss: 1.6550 | Test Acc: 40.97%\n",
      "--------------------------------------------------\n",
      "Epoch 9/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 1.4897 | Train Acc: 46.43%\n",
      "Valid Loss: 1.5235 | Valid Acc: 45.60%\n",
      "Test Loss: 1.5556 | Test Acc: 44.20%\n",
      "--------------------------------------------------\n",
      "Epoch 10/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 1.4350 | Train Acc: 48.62%\n",
      "Valid Loss: 1.6277 | Valid Acc: 41.60%\n",
      "Test Loss: 1.6617 | Test Acc: 40.74%\n",
      "--------------------------------------------------\n",
      "Epoch 11/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.3914 | Train Acc: 50.19%\n",
      "Valid Loss: 1.4686 | Valid Acc: 46.04%\n",
      "Test Loss: 1.5248 | Test Acc: 44.68%\n",
      "--------------------------------------------------\n",
      "Epoch 12/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.3409 | Train Acc: 52.00%\n",
      "Valid Loss: 1.7596 | Valid Acc: 39.10%\n",
      "Test Loss: 1.7913 | Test Acc: 38.77%\n",
      "--------------------------------------------------\n",
      "Epoch 13/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 1.3022 | Train Acc: 53.93%\n",
      "Valid Loss: 1.4195 | Valid Acc: 49.06%\n",
      "Test Loss: 1.4490 | Test Acc: 47.84%\n",
      "--------------------------------------------------\n",
      "Epoch 14/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.2613 | Train Acc: 55.05%\n",
      "Valid Loss: 1.3855 | Valid Acc: 51.44%\n",
      "Test Loss: 1.4397 | Test Acc: 49.99%\n",
      "--------------------------------------------------\n",
      "Epoch 15/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.2233 | Train Acc: 56.51%\n",
      "Valid Loss: 1.3396 | Valid Acc: 52.46%\n",
      "Test Loss: 1.3898 | Test Acc: 51.04%\n",
      "--------------------------------------------------\n",
      "Epoch 16/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.1816 | Train Acc: 57.95%\n",
      "Valid Loss: 1.3519 | Valid Acc: 53.12%\n",
      "Test Loss: 1.3833 | Test Acc: 51.95%\n",
      "--------------------------------------------------\n",
      "Epoch 17/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.1467 | Train Acc: 59.43%\n",
      "Valid Loss: 1.3480 | Valid Acc: 53.96%\n",
      "Test Loss: 1.3986 | Test Acc: 51.81%\n",
      "--------------------------------------------------\n",
      "Epoch 18/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.1034 | Train Acc: 60.83%\n",
      "Valid Loss: 1.3834 | Valid Acc: 52.98%\n",
      "Test Loss: 1.4408 | Test Acc: 51.33%\n",
      "--------------------------------------------------\n",
      "Epoch 19/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.0746 | Train Acc: 62.03%\n",
      "Valid Loss: 1.3421 | Valid Acc: 55.34%\n",
      "Test Loss: 1.4201 | Test Acc: 53.49%\n",
      "--------------------------------------------------\n",
      "Epoch 20/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 1.0213 | Train Acc: 63.83%\n",
      "Valid Loss: 1.2742 | Valid Acc: 56.72%\n",
      "Test Loss: 1.3079 | Test Acc: 56.18%\n",
      "--------------------------------------------------\n",
      "Epoch 21/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.9856 | Train Acc: 65.36%\n",
      "Valid Loss: 1.4436 | Valid Acc: 52.18%\n",
      "Test Loss: 1.4887 | Test Acc: 52.47%\n",
      "--------------------------------------------------\n",
      "Epoch 22/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.9548 | Train Acc: 66.56%\n",
      "Valid Loss: 1.3417 | Valid Acc: 56.04%\n",
      "Test Loss: 1.4110 | Test Acc: 54.07%\n",
      "--------------------------------------------------\n",
      "Epoch 23/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.9113 | Train Acc: 68.06%\n",
      "Valid Loss: 1.3306 | Valid Acc: 55.10%\n",
      "Test Loss: 1.3936 | Test Acc: 54.46%\n",
      "--------------------------------------------------\n",
      "Epoch 24/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.8706 | Train Acc: 69.30%\n",
      "Valid Loss: 1.2594 | Valid Acc: 58.78%\n",
      "Test Loss: 1.3024 | Test Acc: 57.34%\n",
      "--------------------------------------------------\n",
      "Epoch 25/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.8261 | Train Acc: 70.88%\n",
      "Valid Loss: 1.3091 | Valid Acc: 57.64%\n",
      "Test Loss: 1.3789 | Test Acc: 56.48%\n",
      "--------------------------------------------------\n",
      "Epoch 26/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.7908 | Train Acc: 72.15%\n",
      "Valid Loss: 1.4406 | Valid Acc: 55.24%\n",
      "Test Loss: 1.4770 | Test Acc: 54.02%\n",
      "--------------------------------------------------\n",
      "Epoch 27/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.7449 | Train Acc: 73.62%\n",
      "Valid Loss: 1.3508 | Valid Acc: 58.42%\n",
      "Test Loss: 1.4099 | Test Acc: 56.13%\n",
      "--------------------------------------------------\n",
      "Epoch 28/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.7133 | Train Acc: 74.84%\n",
      "Valid Loss: 1.3262 | Valid Acc: 58.16%\n",
      "Test Loss: 1.3942 | Test Acc: 56.56%\n",
      "--------------------------------------------------\n",
      "Epoch 29/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.6722 | Train Acc: 76.16%\n",
      "Valid Loss: 1.5067 | Valid Acc: 55.88%\n",
      "Test Loss: 1.5492 | Test Acc: 54.91%\n",
      "--------------------------------------------------\n",
      "Epoch 30/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.6233 | Train Acc: 77.89%\n",
      "Valid Loss: 1.4594 | Valid Acc: 57.48%\n",
      "Test Loss: 1.5258 | Test Acc: 56.38%\n",
      "--------------------------------------------------\n",
      "Epoch 31/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.5924 | Train Acc: 78.82%\n",
      "Valid Loss: 1.4893 | Valid Acc: 57.16%\n",
      "Test Loss: 1.5416 | Test Acc: 55.61%\n",
      "--------------------------------------------------\n",
      "Epoch 32/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.5539 | Train Acc: 80.37%\n",
      "Valid Loss: 1.4804 | Valid Acc: 57.60%\n",
      "Test Loss: 1.5328 | Test Acc: 57.43%\n",
      "--------------------------------------------------\n",
      "Epoch 33/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.4987 | Train Acc: 82.35%\n",
      "Valid Loss: 1.6834 | Valid Acc: 55.94%\n",
      "Test Loss: 1.7189 | Test Acc: 55.37%\n",
      "--------------------------------------------------\n",
      "Epoch 34/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.4682 | Train Acc: 83.32%\n",
      "Valid Loss: 1.6175 | Valid Acc: 58.18%\n",
      "Test Loss: 1.6717 | Test Acc: 57.42%\n",
      "--------------------------------------------------\n",
      "Epoch 35/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.4350 | Train Acc: 84.42%\n",
      "Valid Loss: 1.5180 | Valid Acc: 59.34%\n",
      "Test Loss: 1.6144 | Test Acc: 58.27%\n",
      "--------------------------------------------------\n",
      "Epoch 36/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.3993 | Train Acc: 85.74%\n",
      "Valid Loss: 1.7517 | Valid Acc: 55.50%\n",
      "Test Loss: 1.8095 | Test Acc: 54.30%\n",
      "--------------------------------------------------\n",
      "Epoch 37/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.3782 | Train Acc: 86.63%\n",
      "Valid Loss: 1.6523 | Valid Acc: 57.68%\n",
      "Test Loss: 1.7457 | Test Acc: 55.92%\n",
      "--------------------------------------------------\n",
      "Epoch 38/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.3433 | Train Acc: 87.86%\n",
      "Valid Loss: 1.6782 | Valid Acc: 58.00%\n",
      "Test Loss: 1.7921 | Test Acc: 56.99%\n",
      "--------------------------------------------------\n",
      "Epoch 39/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.3094 | Train Acc: 89.07%\n",
      "Valid Loss: 1.8504 | Valid Acc: 58.02%\n",
      "Test Loss: 1.8705 | Test Acc: 57.23%\n",
      "--------------------------------------------------\n",
      "Epoch 40/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.2952 | Train Acc: 89.66%\n",
      "Valid Loss: 1.8149 | Valid Acc: 57.24%\n",
      "Test Loss: 1.9059 | Test Acc: 56.20%\n",
      "--------------------------------------------------\n",
      "Epoch 41/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.2704 | Train Acc: 90.38%\n",
      "Valid Loss: 1.9831 | Valid Acc: 57.42%\n",
      "Test Loss: 2.0979 | Test Acc: 55.82%\n",
      "--------------------------------------------------\n",
      "Epoch 42/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.2519 | Train Acc: 91.04%\n",
      "Valid Loss: 1.8952 | Valid Acc: 58.08%\n",
      "Test Loss: 1.9909 | Test Acc: 57.55%\n",
      "--------------------------------------------------\n",
      "Epoch 43/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.2495 | Train Acc: 91.19%\n",
      "Valid Loss: 2.0459 | Valid Acc: 56.42%\n",
      "Test Loss: 2.1378 | Test Acc: 55.22%\n",
      "--------------------------------------------------\n",
      "Epoch 44/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.2247 | Train Acc: 91.86%\n",
      "Valid Loss: 2.0502 | Valid Acc: 58.26%\n",
      "Test Loss: 2.1137 | Test Acc: 57.11%\n",
      "--------------------------------------------------\n",
      "Epoch 45/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.2119 | Train Acc: 92.59%\n",
      "Valid Loss: 1.9453 | Valid Acc: 58.86%\n",
      "Test Loss: 2.0360 | Test Acc: 57.84%\n",
      "--------------------------------------------------\n",
      "Epoch 46/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.1879 | Train Acc: 93.46%\n",
      "Valid Loss: 2.0621 | Valid Acc: 58.86%\n",
      "Test Loss: 2.1616 | Test Acc: 57.99%\n",
      "--------------------------------------------------\n",
      "Epoch 47/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.1960 | Train Acc: 93.09%\n",
      "Valid Loss: 1.9729 | Valid Acc: 59.32%\n",
      "Test Loss: 2.0528 | Test Acc: 58.65%\n",
      "--------------------------------------------------\n",
      "Epoch 48/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.1682 | Train Acc: 93.99%\n",
      "Valid Loss: 2.1217 | Valid Acc: 58.14%\n",
      "Test Loss: 2.2078 | Test Acc: 56.15%\n",
      "--------------------------------------------------\n",
      "Epoch 49/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.1762 | Train Acc: 93.65%\n",
      "Valid Loss: 2.2428 | Valid Acc: 58.12%\n",
      "Test Loss: 2.3434 | Test Acc: 57.00%\n",
      "--------------------------------------------------\n",
      "Epoch 50/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.1645 | Train Acc: 94.26%\n",
      "Valid Loss: 2.0326 | Valid Acc: 59.18%\n",
      "Test Loss: 2.2453 | Test Acc: 56.78%\n",
      "--------------------------------------------------\n",
      "Epoch 51/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.1518 | Train Acc: 94.51%\n",
      "Valid Loss: 2.0274 | Valid Acc: 60.42%\n",
      "Test Loss: 2.2096 | Test Acc: 58.01%\n",
      "--------------------------------------------------\n",
      "Epoch 52/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.1486 | Train Acc: 94.71%\n",
      "Valid Loss: 2.1135 | Valid Acc: 59.10%\n",
      "Test Loss: 2.1556 | Test Acc: 58.24%\n",
      "--------------------------------------------------\n",
      "Epoch 53/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.1445 | Train Acc: 94.95%\n",
      "Valid Loss: 2.0675 | Valid Acc: 59.28%\n",
      "Test Loss: 2.1496 | Test Acc: 58.21%\n",
      "--------------------------------------------------\n",
      "Epoch 54/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.1345 | Train Acc: 95.38%\n",
      "Valid Loss: 2.1698 | Valid Acc: 58.72%\n",
      "Test Loss: 2.2405 | Test Acc: 57.34%\n",
      "--------------------------------------------------\n",
      "Epoch 55/5000:\n",
      "Training time: 10.22 seconds\n",
      "Epoch 00055: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Train Loss: 0.1363 | Train Acc: 95.17%\n",
      "Valid Loss: 2.1779 | Valid Acc: 58.36%\n",
      "Test Loss: 2.2766 | Test Acc: 57.55%\n",
      "--------------------------------------------------\n",
      "Epoch 56/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0461 | Train Acc: 98.62%\n",
      "Valid Loss: 1.9825 | Valid Acc: 62.24%\n",
      "Test Loss: 2.0643 | Test Acc: 61.95%\n",
      "--------------------------------------------------\n",
      "Epoch 57/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0149 | Train Acc: 99.84%\n",
      "Valid Loss: 2.0216 | Valid Acc: 62.00%\n",
      "Test Loss: 2.1140 | Test Acc: 61.79%\n",
      "--------------------------------------------------\n",
      "Epoch 58/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0098 | Train Acc: 99.97%\n",
      "Valid Loss: 2.0557 | Valid Acc: 62.40%\n",
      "Test Loss: 2.1293 | Test Acc: 62.16%\n",
      "--------------------------------------------------\n",
      "Epoch 59/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0076 | Train Acc: 99.97%\n",
      "Valid Loss: 2.0928 | Valid Acc: 62.42%\n",
      "Test Loss: 2.2017 | Test Acc: 62.21%\n",
      "--------------------------------------------------\n",
      "Epoch 60/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0063 | Train Acc: 99.98%\n",
      "Valid Loss: 2.1094 | Valid Acc: 62.50%\n",
      "Test Loss: 2.2391 | Test Acc: 62.10%\n",
      "--------------------------------------------------\n",
      "Epoch 61/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0053 | Train Acc: 99.99%\n",
      "Valid Loss: 2.1194 | Valid Acc: 62.84%\n",
      "Test Loss: 2.2162 | Test Acc: 62.32%\n",
      "--------------------------------------------------\n",
      "Epoch 62/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0046 | Train Acc: 99.99%\n",
      "Valid Loss: 2.1453 | Valid Acc: 62.58%\n",
      "Test Loss: 2.2274 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 63/5000:\n",
      "Training time: 10.34 seconds\n",
      "Train Loss: 0.0041 | Train Acc: 99.99%\n",
      "Valid Loss: 2.1753 | Valid Acc: 62.60%\n",
      "Test Loss: 2.2823 | Test Acc: 62.20%\n",
      "--------------------------------------------------\n",
      "Epoch 64/5000:\n",
      "Training time: 10.34 seconds\n",
      "Train Loss: 0.0036 | Train Acc: 99.99%\n",
      "Valid Loss: 2.1665 | Valid Acc: 62.78%\n",
      "Test Loss: 2.2336 | Test Acc: 62.15%\n",
      "--------------------------------------------------\n",
      "Epoch 65/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0033 | Train Acc: 100.00%\n",
      "Valid Loss: 2.1865 | Valid Acc: 62.62%\n",
      "Test Loss: 2.2640 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 66/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0031 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2238 | Valid Acc: 62.94%\n",
      "Test Loss: 2.3133 | Test Acc: 62.16%\n",
      "--------------------------------------------------\n",
      "Epoch 67/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.0029 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2173 | Valid Acc: 62.92%\n",
      "Test Loss: 2.3076 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 68/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0026 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2452 | Valid Acc: 62.70%\n",
      "Test Loss: 2.3302 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 69/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0024 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2413 | Valid Acc: 62.76%\n",
      "Test Loss: 2.3414 | Test Acc: 62.25%\n",
      "--------------------------------------------------\n",
      "Epoch 70/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0022 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2622 | Valid Acc: 62.64%\n",
      "Test Loss: 2.3876 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 71/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0022 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2704 | Valid Acc: 62.66%\n",
      "Test Loss: 2.3313 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 72/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0022 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2942 | Valid Acc: 62.90%\n",
      "Test Loss: 2.3634 | Test Acc: 61.97%\n",
      "--------------------------------------------------\n",
      "Epoch 73/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0019 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3028 | Valid Acc: 62.78%\n",
      "Test Loss: 2.3744 | Test Acc: 62.15%\n",
      "--------------------------------------------------\n",
      "Epoch 74/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0019 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2893 | Valid Acc: 62.70%\n",
      "Test Loss: 2.3780 | Test Acc: 61.94%\n",
      "--------------------------------------------------\n",
      "Epoch 75/5000:\n",
      "Training time: 10.35 seconds\n",
      "Train Loss: 0.0018 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3006 | Valid Acc: 62.88%\n",
      "Test Loss: 2.3762 | Test Acc: 61.84%\n",
      "--------------------------------------------------\n",
      "Epoch 76/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0018 | Train Acc: 100.00%\n",
      "Valid Loss: 2.2986 | Valid Acc: 62.56%\n",
      "Test Loss: 2.4386 | Test Acc: 62.13%\n",
      "--------------------------------------------------\n",
      "Epoch 77/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0017 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3080 | Valid Acc: 62.52%\n",
      "Test Loss: 2.3640 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 78/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0015 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3152 | Valid Acc: 62.62%\n",
      "Test Loss: 2.3934 | Test Acc: 62.19%\n",
      "--------------------------------------------------\n",
      "Epoch 79/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0015 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3176 | Valid Acc: 62.78%\n",
      "Test Loss: 2.4407 | Test Acc: 62.10%\n",
      "--------------------------------------------------\n",
      "Epoch 80/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0015 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3276 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4334 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 81/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0014 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3266 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4381 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 82/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0014 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3353 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4914 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 83/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0014 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3407 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4204 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 84/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0013 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3226 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4634 | Test Acc: 61.96%\n",
      "--------------------------------------------------\n",
      "Epoch 85/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0013 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3527 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4184 | Test Acc: 62.06%\n",
      "--------------------------------------------------\n",
      "Epoch 86/5000:\n",
      "Training time: 10.31 seconds\n",
      "Epoch 00086: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3528 | Valid Acc: 62.70%\n",
      "Test Loss: 2.4370 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 87/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3559 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4685 | Test Acc: 62.06%\n",
      "--------------------------------------------------\n",
      "Epoch 88/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3395 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4025 | Test Acc: 62.20%\n",
      "--------------------------------------------------\n",
      "Epoch 89/5000:\n",
      "Training time: 10.36 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3389 | Valid Acc: 62.86%\n",
      "Test Loss: 2.3856 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 90/5000:\n",
      "Training time: 10.42 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3616 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4267 | Test Acc: 62.18%\n",
      "--------------------------------------------------\n",
      "Epoch 91/5000:\n",
      "Training time: 10.41 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3411 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4423 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 92/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3500 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4154 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 93/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3364 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4802 | Test Acc: 61.96%\n",
      "--------------------------------------------------\n",
      "Epoch 94/5000:\n",
      "Training time: 10.41 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3523 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4541 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 95/5000:\n",
      "Training time: 10.37 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3454 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4319 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 96/5000:\n",
      "Training time: 10.38 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3545 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4535 | Test Acc: 62.10%\n",
      "--------------------------------------------------\n",
      "Epoch 97/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3437 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4528 | Test Acc: 62.06%\n",
      "--------------------------------------------------\n",
      "Epoch 98/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3632 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4427 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 99/5000:\n",
      "Training time: 10.38 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3486 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4273 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 100/5000:\n",
      "Training time: 10.38 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3388 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4063 | Test Acc: 62.06%\n",
      "--------------------------------------------------\n",
      "Epoch 101/5000:\n",
      "Training time: 10.31 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3444 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4052 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 102/5000:\n",
      "Training time: 10.30 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3364 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4206 | Test Acc: 61.97%\n",
      "--------------------------------------------------\n",
      "Epoch 103/5000:\n",
      "Training time: 10.31 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3455 | Valid Acc: 63.10%\n",
      "Test Loss: 2.4345 | Test Acc: 61.94%\n",
      "--------------------------------------------------\n",
      "Epoch 104/5000:\n",
      "Training time: 10.29 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3569 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4534 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 105/5000:\n",
      "Training time: 10.29 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3338 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4425 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 106/5000:\n",
      "Training time: 10.29 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3787 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4460 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 107/5000:\n",
      "Training time: 10.30 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3540 | Valid Acc: 62.68%\n",
      "Test Loss: 2.4388 | Test Acc: 62.22%\n",
      "--------------------------------------------------\n",
      "Epoch 108/5000:\n",
      "Training time: 10.30 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3505 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4147 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 109/5000:\n",
      "Training time: 10.29 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3623 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4194 | Test Acc: 62.16%\n",
      "--------------------------------------------------\n",
      "Epoch 110/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3488 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4650 | Test Acc: 62.02%\n",
      "--------------------------------------------------\n",
      "Epoch 111/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3603 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4543 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 112/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3684 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4214 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 113/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3620 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4167 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 114/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3537 | Valid Acc: 62.82%\n",
      "Test Loss: 2.5098 | Test Acc: 62.20%\n",
      "--------------------------------------------------\n",
      "Epoch 115/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3446 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4611 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 116/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3475 | Valid Acc: 62.72%\n",
      "Test Loss: 2.4080 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 117/5000:\n",
      "Training time: 10.20 seconds\n",
      "Epoch 00117: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3515 | Valid Acc: 62.78%\n",
      "Test Loss: 2.4282 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 118/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3477 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4162 | Test Acc: 62.15%\n",
      "--------------------------------------------------\n",
      "Epoch 119/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3456 | Valid Acc: 62.72%\n",
      "Test Loss: 2.4384 | Test Acc: 62.10%\n",
      "--------------------------------------------------\n",
      "Epoch 120/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3417 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4653 | Test Acc: 61.94%\n",
      "--------------------------------------------------\n",
      "Epoch 121/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3833 | Valid Acc: 62.72%\n",
      "Test Loss: 2.4747 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 122/5000:\n",
      "Training time: 10.19 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3670 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4537 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 123/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3411 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4340 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 124/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3810 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4223 | Test Acc: 62.24%\n",
      "--------------------------------------------------\n",
      "Epoch 125/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3825 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4773 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 126/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3402 | Valid Acc: 63.12%\n",
      "Test Loss: 2.4912 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 127/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3767 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4706 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 128/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3482 | Valid Acc: 62.72%\n",
      "Test Loss: 2.4273 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 129/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3590 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4605 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 130/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3541 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4197 | Test Acc: 61.98%\n",
      "--------------------------------------------------\n",
      "Epoch 131/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3600 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4363 | Test Acc: 61.92%\n",
      "--------------------------------------------------\n",
      "Epoch 132/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3718 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4674 | Test Acc: 62.00%\n",
      "--------------------------------------------------\n",
      "Epoch 133/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3545 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4314 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 134/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3547 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4403 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 135/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3416 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4342 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 136/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3707 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4391 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 137/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3850 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4314 | Test Acc: 62.22%\n",
      "--------------------------------------------------\n",
      "Epoch 138/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3410 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4492 | Test Acc: 61.95%\n",
      "--------------------------------------------------\n",
      "Epoch 139/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3612 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4092 | Test Acc: 61.98%\n",
      "--------------------------------------------------\n",
      "Epoch 140/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3409 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4652 | Test Acc: 62.00%\n",
      "--------------------------------------------------\n",
      "Epoch 141/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3611 | Valid Acc: 62.66%\n",
      "Test Loss: 2.4436 | Test Acc: 62.16%\n",
      "--------------------------------------------------\n",
      "Epoch 142/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3499 | Valid Acc: 62.70%\n",
      "Test Loss: 2.4741 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 143/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3261 | Valid Acc: 62.88%\n",
      "Test Loss: 2.3986 | Test Acc: 61.98%\n",
      "--------------------------------------------------\n",
      "Epoch 144/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3535 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4311 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 145/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3644 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4525 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 146/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3745 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4392 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 147/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3371 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4086 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 148/5000:\n",
      "Training time: 10.23 seconds\n",
      "Epoch 00148: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3605 | Valid Acc: 63.06%\n",
      "Test Loss: 2.4561 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 149/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3680 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4654 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 150/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3676 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4278 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 151/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3491 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4488 | Test Acc: 61.99%\n",
      "--------------------------------------------------\n",
      "Epoch 152/5000:\n",
      "Training time: 10.34 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3636 | Valid Acc: 62.78%\n",
      "Test Loss: 2.4906 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 153/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3518 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4192 | Test Acc: 61.87%\n",
      "--------------------------------------------------\n",
      "Epoch 154/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3708 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4175 | Test Acc: 62.13%\n",
      "--------------------------------------------------\n",
      "Epoch 155/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3513 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4167 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 156/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3392 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4621 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 157/5000:\n",
      "Training time: 10.37 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3532 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4382 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 158/5000:\n",
      "Training time: 10.25 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3778 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4234 | Test Acc: 62.21%\n",
      "--------------------------------------------------\n",
      "Epoch 159/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3648 | Valid Acc: 62.72%\n",
      "Test Loss: 2.4635 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 160/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3597 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4467 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 161/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3537 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4437 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 162/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3489 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4279 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 163/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3550 | Valid Acc: 62.98%\n",
      "Test Loss: 2.4061 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 164/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3587 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4347 | Test Acc: 62.25%\n",
      "--------------------------------------------------\n",
      "Epoch 165/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3617 | Valid Acc: 62.62%\n",
      "Test Loss: 2.4295 | Test Acc: 62.13%\n",
      "--------------------------------------------------\n",
      "Epoch 166/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3728 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4704 | Test Acc: 62.13%\n",
      "--------------------------------------------------\n",
      "Epoch 167/5000:\n",
      "Training time: 10.20 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3689 | Valid Acc: 62.78%\n",
      "Test Loss: 2.4235 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 168/5000:\n",
      "Training time: 10.21 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3511 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4523 | Test Acc: 61.97%\n",
      "--------------------------------------------------\n",
      "Epoch 169/5000:\n",
      "Training time: 10.31 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3699 | Valid Acc: 62.58%\n",
      "Test Loss: 2.4578 | Test Acc: 62.18%\n",
      "--------------------------------------------------\n",
      "Epoch 170/5000:\n",
      "Training time: 10.39 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3501 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4654 | Test Acc: 61.99%\n",
      "--------------------------------------------------\n",
      "Epoch 171/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3431 | Valid Acc: 62.98%\n",
      "Test Loss: 2.4162 | Test Acc: 62.10%\n",
      "--------------------------------------------------\n",
      "Epoch 172/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3661 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4753 | Test Acc: 62.12%\n",
      "--------------------------------------------------\n",
      "Epoch 173/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3363 | Valid Acc: 63.04%\n",
      "Test Loss: 2.4338 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 174/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3534 | Valid Acc: 62.68%\n",
      "Test Loss: 2.4411 | Test Acc: 61.98%\n",
      "--------------------------------------------------\n",
      "Epoch 175/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3648 | Valid Acc: 62.74%\n",
      "Test Loss: 2.4599 | Test Acc: 62.01%\n",
      "--------------------------------------------------\n",
      "Epoch 176/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3401 | Valid Acc: 63.06%\n",
      "Test Loss: 2.4523 | Test Acc: 62.24%\n",
      "--------------------------------------------------\n",
      "Epoch 177/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3488 | Valid Acc: 62.98%\n",
      "Test Loss: 2.4445 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 178/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3683 | Valid Acc: 62.62%\n",
      "Test Loss: 2.4636 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 179/5000:\n",
      "Training time: 10.23 seconds\n",
      "Epoch 00179: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3510 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4753 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 180/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3690 | Valid Acc: 63.00%\n",
      "Test Loss: 2.4508 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 181/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3566 | Valid Acc: 62.96%\n",
      "Test Loss: 2.3930 | Test Acc: 62.15%\n",
      "--------------------------------------------------\n",
      "Epoch 182/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3497 | Valid Acc: 62.70%\n",
      "Test Loss: 2.4378 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 183/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3526 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4253 | Test Acc: 62.18%\n",
      "--------------------------------------------------\n",
      "Epoch 184/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3577 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4876 | Test Acc: 61.99%\n",
      "--------------------------------------------------\n",
      "Epoch 185/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3596 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4150 | Test Acc: 61.97%\n",
      "--------------------------------------------------\n",
      "Epoch 186/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3659 | Valid Acc: 62.64%\n",
      "Test Loss: 2.4619 | Test Acc: 62.07%\n",
      "--------------------------------------------------\n",
      "Epoch 187/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3611 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4432 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 188/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3701 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4851 | Test Acc: 62.06%\n",
      "--------------------------------------------------\n",
      "Epoch 189/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3443 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4455 | Test Acc: 62.17%\n",
      "--------------------------------------------------\n",
      "Epoch 190/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3545 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4500 | Test Acc: 61.99%\n",
      "--------------------------------------------------\n",
      "Epoch 191/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3662 | Valid Acc: 62.76%\n",
      "Test Loss: 2.4263 | Test Acc: 61.92%\n",
      "--------------------------------------------------\n",
      "Epoch 192/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3543 | Valid Acc: 62.80%\n",
      "Test Loss: 2.4761 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 193/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3497 | Valid Acc: 62.92%\n",
      "Test Loss: 2.4438 | Test Acc: 61.96%\n",
      "--------------------------------------------------\n",
      "Epoch 194/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3626 | Valid Acc: 62.70%\n",
      "Test Loss: 2.4413 | Test Acc: 62.16%\n",
      "--------------------------------------------------\n",
      "Epoch 195/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0012 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3656 | Valid Acc: 62.98%\n",
      "Test Loss: 2.4905 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 196/5000:\n",
      "Training time: 10.22 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3578 | Valid Acc: 62.90%\n",
      "Test Loss: 2.5029 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 197/5000:\n",
      "Training time: 10.23 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3447 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4224 | Test Acc: 62.15%\n",
      "--------------------------------------------------\n",
      "Epoch 198/5000:\n",
      "Training time: 10.24 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3541 | Valid Acc: 62.82%\n",
      "Test Loss: 2.4312 | Test Acc: 62.14%\n",
      "--------------------------------------------------\n",
      "Epoch 199/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3597 | Valid Acc: 62.90%\n",
      "Test Loss: 2.4641 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 200/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3599 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4387 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 201/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3448 | Valid Acc: 62.88%\n",
      "Test Loss: 2.4630 | Test Acc: 61.90%\n",
      "--------------------------------------------------\n",
      "Epoch 202/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3610 | Valid Acc: 63.02%\n",
      "Test Loss: 2.4613 | Test Acc: 62.04%\n",
      "--------------------------------------------------\n",
      "Epoch 203/5000:\n",
      "Training time: 10.33 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3647 | Valid Acc: 62.84%\n",
      "Test Loss: 2.4347 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 204/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3486 | Valid Acc: 62.78%\n",
      "Test Loss: 2.4683 | Test Acc: 62.05%\n",
      "--------------------------------------------------\n",
      "Epoch 205/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3627 | Valid Acc: 63.06%\n",
      "Test Loss: 2.4530 | Test Acc: 62.18%\n",
      "--------------------------------------------------\n",
      "Epoch 206/5000:\n",
      "Training time: 10.34 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3393 | Valid Acc: 62.94%\n",
      "Test Loss: 2.4605 | Test Acc: 62.08%\n",
      "--------------------------------------------------\n",
      "Epoch 207/5000:\n",
      "Training time: 10.31 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3524 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4915 | Test Acc: 62.13%\n",
      "--------------------------------------------------\n",
      "Epoch 208/5000:\n",
      "Training time: 10.31 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3427 | Valid Acc: 63.02%\n",
      "Test Loss: 2.4294 | Test Acc: 62.03%\n",
      "--------------------------------------------------\n",
      "Epoch 209/5000:\n",
      "Training time: 10.32 seconds\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3417 | Valid Acc: 62.86%\n",
      "Test Loss: 2.4326 | Test Acc: 62.11%\n",
      "--------------------------------------------------\n",
      "Epoch 210/5000:\n",
      "Training time: 10.31 seconds\n",
      "Epoch 00210: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Valid Loss: 2.3495 | Valid Acc: 62.96%\n",
      "Test Loss: 2.4312 | Test Acc: 62.09%\n",
      "--------------------------------------------------\n",
      "Epoch 211/5000:\n"
     ]
    }
   ],
   "source": [
    "_log_train_loss = []\n",
    "_log_train_acc = []\n",
    "_log_valid_loss = []\n",
    "_log_valid_acc = []\n",
    "_log_test_loss = []\n",
    "_log_test_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}:\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Training time: {execution_time:.2f} seconds\")\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_acc = correct / total\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc = correct / total\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc*100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "    _log_train_loss.append(train_loss)\n",
    "    _log_train_acc.append(train_acc)\n",
    "    _log_valid_loss.append(valid_loss)\n",
    "    _log_valid_acc.append(valid_acc)\n",
    "    _log_test_loss.append(test_loss)\n",
    "    _log_test_acc.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Training:\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def __call__(self):\n",
    "#         print(f\"Epoch {self.now_count+1}/{self.num_epochs}:\")\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # Training loop\n",
    "#         self.model.train()\n",
    "#         running_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         for images, labels in train_dataloader:\n",
    "#             images, labels = images.to(self.devic), labels.to(self.devic)\n",
    "\n",
    "#             self.optimizer.zero_grad()\n",
    "#             outputs = self.model(images)\n",
    "#             loss = self.criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         tmp_loss = running_loss / len(train_dataloader)\n",
    "#         tmp_acc = correct / total\n",
    "\n",
    "#         end_time = time.time()\n",
    "#         execution_time = end_time - start_time\n",
    "#         print(f\"Training time: {execution_time:.2f} seconds\")\n",
    "\n",
    "#         self._log_train_loss.append(tmp_loss)\n",
    "#         self._log_train_acc.append(tmp_acc)\n",
    "#         print(f\"Train Loss: {tmp_loss:.4f} | Train Acc: {tmp_acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "# class Evaluation:\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def __call__(self, mode):\n",
    "#         # Evaluation loop\n",
    "#         self.model.eval()\n",
    "#         tmp_loss = 0.0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         if mode == \"Valid\":\n",
    "#             some_dataloader = self.valid_dataloader\n",
    "#         elif mode == \"Test\":\n",
    "#             some_dataloader = self.test_dataloader\n",
    "#         else:\n",
    "#             raise Exception(\"Mode Error in Evaluation ...\")\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in some_dataloader:\n",
    "#                 images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "#                 outputs = self.model(images)\n",
    "#                 loss = self.criterion(outputs, labels)\n",
    "\n",
    "#                 tmp_loss += loss.item()\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "#         tmp_loss /= len(valid_dataloader)\n",
    "#         tmp_acc = correct / total\n",
    "#         \"\"\"\n",
    "#         validation loss가 평평할 때에 divide by 10\n",
    "#         \"\"\"\n",
    "#         if mode == \"Valid\":\n",
    "#             self.scheduler.step(tmp_loss)\n",
    "#             self._log_valid_loss.append(tmp_loss)\n",
    "#             self._log_valid_acc.append(tmp_acc)\n",
    "#         elif mode == \"Test\":\n",
    "#             self._log_test_loss.append(tmp_loss)\n",
    "#             self._log_test_acc.append(tmp_acc)\n",
    "#         else:\n",
    "#             raise Exception(\"Mode Error in Evaluation ...\")\n",
    "\n",
    "#         print(f\"{mode} Loss: {tmp_loss:.4f} | {mode} Acc: {tmp_acc*100:.2f}%\")\n",
    "#         return\n",
    "\n",
    "\n",
    "# class DoTraining(object):\n",
    "#     def __init__(self, model, num_epochs, datasets) -> None:\n",
    "#         self.device = (\n",
    "#             \"cuda\"\n",
    "#             if torch.cuda.is_available()\n",
    "#             else \"mps\"\n",
    "#             if torch.backends.mps.is_available()\n",
    "#             else \"cpu\"\n",
    "#         )\n",
    "#         print(f\"- Using {self.device} device\")\n",
    "\n",
    "#         self.model = model\n",
    "#         self.train_class = Training()\n",
    "#         self.eval_class = Evaluation()\n",
    "#         self.num_epochs = num_epochs\n",
    "#         self.now_count = 0\n",
    "#         self.train_dataloader, self.valid_dataloader, self.test_dataloader = datasets\n",
    "\n",
    "#         total_params = sum(p.numel() for p in model.parameters())\n",
    "#         print(f\"- Number of total parameters: {total_params/1e6:2.2f}M\")\n",
    "\n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#         self.optimizer = torch.optim.SGD(\n",
    "#             model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001\n",
    "#         )\n",
    "#         # self.optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "#         self.scheduler = ReduceLROnPlateau(\n",
    "#             self.optimizer,\n",
    "#             mode=\"min\",\n",
    "#             patience=3,\n",
    "#             factor=0.1,\n",
    "#             verbose=True,\n",
    "#             threshold=2,\n",
    "#         )\n",
    "#         \"\"\"\n",
    "#         ReduceLROnPlateau 스케줄러는 mode='min'으로 설정되어 손실이 감소해야 학습률을 조절합니다. \n",
    "#         patience는 얼마나 기다렸다가 학습률을 조절할지를 결정하며, \n",
    "#         factor는 학습률을 조절할 때 사용할 인수입니다. \n",
    "#         >> now learning의 0.1로 조정 >> divide by 10\n",
    "#         verbose=True로 설정하면 언제 학습률이 조절되었는지 출력됩니다.\n",
    "#         https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "#         \"\"\"\n",
    "\n",
    "#         self._log_train_loss = []\n",
    "#         self._log_train_acc = []\n",
    "#         self._log_valid_loss = []\n",
    "#         self._log_valid_acc = []\n",
    "#         self._log_test_loss = []\n",
    "#         self._log_test_acc = []\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def Run(self):\n",
    "#         for self.now_count in range(self.num_epochs):\n",
    "#             self.train_class()\n",
    "#             self.now_count += 1\n",
    "#             self.eval_class(mode=\"Valid\")\n",
    "#             self.eval_class(mode=\"Test\")\n",
    "#             print(\"-\" * 50)\n",
    "#         return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# 첫 번째 그래프: Training and Test Loss\n",
    "axs[0].plot(_log_train_loss, label=\"Training Loss\")\n",
    "axs[0].plot(_log_valid_loss, label=\"Validation Loss\")\n",
    "axs[0].plot(_log_test_loss, label=\"Test Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_title(\"Training, Validation and Test Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# 두 번째 그래프: Training and Test Accuracy\n",
    "axs[1].plot(_log_train_acc, label=\"Training Accuracy\")\n",
    "axs[1].plot(_log_valid_acc, label=\"Validation Accuracy\")\n",
    "axs[1].plot(_log_test_acc, label=\"Test Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].set_title(\"Training, Validation and Test Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "# 그래프를 보여줍니다.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"models/Myresnet34.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyResNet34(Block, COUNT_OF_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(\"models/Myresnet34.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
