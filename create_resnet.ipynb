{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms.v2 import (\n",
    "    ToTensor,\n",
    "    RandomHorizontalFlip,\n",
    "    Compose,\n",
    "    RandomResizedCrop,\n",
    "    RandomShortestSize,\n",
    "    AutoAugment,\n",
    ")\n",
    "\n",
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "# DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 256\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "\n",
    "\"\"\"training parameters\"\"\"\n",
    "# ImageNet정도 대규모 일 때에 조금 효과있는 것 같아서, CIFAF에서는 제외.\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    USE_AMP = True\n",
    "else:\n",
    "    USE_AMP = False\n",
    "\n",
    "# USE_AMP = False\n",
    "\n",
    "LOAD_BEFORE_WEIGHTS = False\n",
    "\n",
    "NUM_EPOCHS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dateloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Submean(torch.nn.Module):\n",
    "    # Subtract the mean from each pixel along each channel\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        return None\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        _mean = tensor.mean(axis=(1, 2))\n",
    "        tensor = tensor - _mean[:, None, None]\n",
    "\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class PaddingWithRandomResizedCrop(RandomResizedCrop):\n",
    "    # Add padding to the image\n",
    "    def __call__(self, img):\n",
    "        img = F.pad(img, (4, 4, 4, 4), mode=\"constant\", value=0)\n",
    "        return super().__call__(img)\n",
    "\n",
    "\n",
    "class LoadDataset:\n",
    "    \"\"\"\n",
    "    input :\n",
    "        - root : \"data\"\n",
    "        - seceted_data :\n",
    "            - \"CIFAR10\" or \"CIFAR100\" : Load ~ from torchvision.datasets\n",
    "            - \"ImageNet2012\" : Load ~ from Local\n",
    "    pre-processing:\n",
    "        - CIFAR10, CIFAR100 :\n",
    "            - split train/valid with 9:1 ratio\n",
    "            - train :\n",
    "                ToTensor(),\n",
    "                Random Horizontal Flip (p = 0.5),\n",
    "                4 pixel zero padding and crop to (32,32,3),\n",
    "                Submean(),\n",
    "            - valid, test :\n",
    "                ToTensor(),\n",
    "                Submean(),\n",
    "        - ImageNet2012 :\n",
    "            - train :\n",
    "                ToTensor(),\n",
    "                RandomShortestSize(min_size=256, max_size=480, antialias=True),\n",
    "                RandomResizedCrop([224, 224], antialias=True),\n",
    "                RandomHorizontalFlip(self.Randp),\n",
    "                Submean(),\n",
    "            - valid :\n",
    "                ToTensor(),\n",
    "                RandomShortestSize(min_size=[224, 256, 384, 480, 640], antialias=True),\n",
    "                RandomResizedCrop([224, 224], antialias=True),\n",
    "                Submean(),\n",
    "    output :\n",
    "        - self.train_data\n",
    "        - self.valid_data\n",
    "        - self.test_data\n",
    "        - num of classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, seceted_dataset=\"CIFAR100\"):\n",
    "        self.Randp = 0.5\n",
    "        self.dataset_name = seceted_dataset\n",
    "\n",
    "        if self.dataset_name[:5] == \"CIFAR\":\n",
    "            self.split_ratio = 0.9\n",
    "            dataset_mapping = {\n",
    "                \"CIFAR100\": datasets.CIFAR100,\n",
    "                \"CIFAR10\": datasets.CIFAR10,\n",
    "                # Add more datasets if needed\n",
    "            }\n",
    "            cifar_default_transforms = Compose(\n",
    "                [\n",
    "                    ToTensor(),\n",
    "                    Submean(),\n",
    "                ],\n",
    "            )\n",
    "            \"\"\"CIFAR10, CIFAR100에서는 ref_train에 split ratio대로 적용해서 잘라냄.\"\"\"\n",
    "            ref_train = dataset_mapping[self.dataset_name](\n",
    "                root=root,\n",
    "                train=True,\n",
    "                download=False,\n",
    "                transform=cifar_default_transforms,\n",
    "            )\n",
    "            self.test_data = dataset_mapping[self.dataset_name](\n",
    "                root=root,\n",
    "                train=False,\n",
    "                download=False,\n",
    "                transform=cifar_default_transforms,\n",
    "            )\n",
    "            # Split to train and valid set\n",
    "            total_length = len(ref_train)\n",
    "            train_length = int(total_length * self.split_ratio)\n",
    "            valid_length = total_length - train_length\n",
    "            self.train_data, self.valid_data = random_split(\n",
    "                ref_train, [train_length, valid_length]\n",
    "            )\n",
    "            # Apply transform at each dataset\n",
    "            self.train_data.transform = copy.deepcopy(cifar_default_transforms)\n",
    "            self.valid_data.transform = copy.deepcopy(cifar_default_transforms)\n",
    "\n",
    "            ####### 둘 중 하나 골라서 #################################\n",
    "            # self.train_data.transform.transforms.append(PaddingWithRandomResizedCrop([32, 32]))\n",
    "            self.train_data.transform.transforms.append(\n",
    "                AutoAugment(policy=AutoAugmentPolicy.CIFAR10)\n",
    "            )\n",
    "            #######################################################\n",
    "            \n",
    "            self.train_data.transform.transforms.append(\n",
    "                RandomHorizontalFlip(self.Randp),\n",
    "            )\n",
    "            # Copy classes data\n",
    "            self.train_data.classes = ref_train.classes\n",
    "            self.valid_data.classes = ref_train.classes\n",
    "\n",
    "            self.train_data.class_to_idx = ref_train.class_to_idx\n",
    "            self.valid_data.class_to_idx = ref_train.class_to_idx\n",
    "\n",
    "        elif self.dataset_name == \"ImageNet2012\":\n",
    "            self.ImageNetRoot = \"data/\" + self.dataset_name + \"/\"\n",
    "\n",
    "            self.train_data = datasets.ImageFolder(\n",
    "                root=self.ImageNetRoot + \"train\",\n",
    "                transform=Compose(\n",
    "                    [\n",
    "                        ToTensor(),\n",
    "                        Submean(),\n",
    "                        # with AutoAugment\n",
    "                        AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "                        RandomShortestSize(min_size=256, max_size=480, antialias=True),\n",
    "                        RandomResizedCrop([224, 224], antialias=True),\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "            self.valid_data = datasets.ImageFolder(\n",
    "                root=self.ImageNetRoot + \"val\",\n",
    "                transform=Compose(\n",
    "                    [\n",
    "                        ToTensor(),\n",
    "                        Submean(),\n",
    "                        # RandomShortestSize(\n",
    "                        #     min_size=[224, 256, 384, 480, 640], antialias=True\n",
    "                        # ),\n",
    "                        # RandomResizedCrop([224, 224], antialias=True),\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "            self.test_data = self.valid_data\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dataset: {self.dataset_name}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def unpack(self):\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"Dataset : \", self.dataset_name)\n",
    "        print(\"- Length of Train Set : \", len(self.train_data))\n",
    "        print(\"- Length of Valid Set : \", len(self.valid_data))\n",
    "        if self.dataset_name == \"ImageNet\":\n",
    "            pass\n",
    "        else:\n",
    "            print(\"- Length of Test Set : \", len(self.test_data))\n",
    "        print(\"- Count of Classes : \", len(self.train_data.classes))\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        return (\n",
    "            self.train_data,\n",
    "            self.valid_data,\n",
    "            self.test_data,\n",
    "            len(self.train_data.classes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that the dataset is loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = LoadDataset(root=\"data\", seceted_dataset=DATASET)\n",
    "train_data, valid_data, test_data, COUNT_OF_CLASSES = _dataset.unpack()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=NUMOFWORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    # pin_memory_device=\"cuda\",\n",
    "    persistent_workers=True,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=NUMOFWORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    # pin_memory_device=\"cuda\",\n",
    "    persistent_workers=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=NUMOFWORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    # pin_memory_device=\"cuda\",\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "print(\"train.transforms =\", train_data.transform)\n",
    "print(\"valid.transforms =\", valid_data.transform)\n",
    "print(\"test.transforms =\", test_data.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader.batch_size)\n",
    "print(valid_dataloader.batch_size)\n",
    "print(test_dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET != \"ImageNet2012\":\n",
    "    for X, y in test_dataloader:\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(\"mean of X\", X.mean(dim=(0, 2, 3)))\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET != \"ImageNet2012\":\n",
    "    # Get the class names\n",
    "    class_names = test_dataloader.dataset.classes\n",
    "    count = 0\n",
    "\n",
    "    # Create a subplot with 2 rows and 5 columns\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(8, 4))\n",
    "\n",
    "    # Iterate over the first batch of images and labels\n",
    "    for images, labels in test_dataloader:\n",
    "        # Convert the images to numpy arrays\n",
    "        images = images.numpy()\n",
    "        \n",
    "        # Iterate over the images and labels\n",
    "        for i in range(len(images)):\n",
    "            # Get the image and label\n",
    "            image = images[i]\n",
    "            label = labels[i]\n",
    "            \n",
    "            # Convert the image from tensor to numpy array\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "            \n",
    "            # Plot the image in the appropriate subplot\n",
    "            ax = axs[count // 5, count % 5]\n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"{class_names[label], label}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Increment the count\n",
    "            count += 1\n",
    "            \n",
    "            # Break the loop if we have displayed 10 images\n",
    "            if count == 10:\n",
    "                break\n",
    "                \n",
    "        # Break the loop if we have displayed 10 images\n",
    "        if count == 10:\n",
    "            break\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    - Downsample_option :\n",
    "        (A) zero-padding shortcuts are used for increasing dimensions, \n",
    "            and all shortcuts are parameter- free (the same as Table 2 and Fig. 4 right); \n",
    "        (B) projection shortcuts are used for increasing dimensions, and other shortcuts are identity;\n",
    "        (C) all shortcuts are projections.\n",
    "    \"\"\"\n",
    "    def __init__(self, inputs, outputs, Downsample_option=None, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.Downsample_option = Downsample_option\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inputs, outputs, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(outputs, eps=1e-05, momentum=0.1)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "        self.conv2 = nn.Conv2d(outputs, outputs, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(outputs, eps=1e-05, momentum=0.1)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "\n",
    "        if self.Downsample_option == \"A\":\n",
    "            self.conv1.stride = 2\n",
    "\n",
    "        if self.Downsample_option == \"C\":\n",
    "            self.conv1.stride = 2\n",
    "            self.conv_down = nn.Conv2d(\n",
    "                inputs, outputs, kernel_size=1, stride=2, bias=False\n",
    "            )\n",
    "            # 여기 BN빼니까 완전히 망가져버림. acc 10% 찍힘.\n",
    "            nn.init.kaiming_normal_(\n",
    "                self.conv_down.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "            )\n",
    "            self.bn_down = nn.BatchNorm2d(\n",
    "                outputs,\n",
    "                eps=1e-05,\n",
    "                momentum=0.1,\n",
    "                affine=True,\n",
    "                track_running_stats=True,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x1(identity) :\", x.shape)\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # print(\"x2 :\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.Downsample_option == \"A\":\n",
    "            identity = F.max_pool2d(identity, kernel_size=2, stride=2)\n",
    "            identity = torch.cat(\n",
    "                [identity, torch.zeros(identity.shape).to(self.device)], dim=1\n",
    "            )\n",
    "        elif self.Downsample_option == \"C\":\n",
    "            identity = self.conv_down(identity)\n",
    "            identity = self.bn_down(identity)\n",
    "\n",
    "        # print(\"x3(downsampled) :\", identity.shape)\n",
    "        # print(\"x4 :\", identity.shape)\n",
    "        x = x + identity  # 여기 x+=identity로 하면 안 됨. inplace operation이라서.\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet34(nn.Module):\n",
    "    def __init__(self, num_classes, BlockClass=Block):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.BlockClass = BlockClass\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv64blocks = nn.Sequential(\n",
    "            self.BlockClass(64, 64), self.BlockClass(64, 64), self.BlockClass(64, 64)\n",
    "        )\n",
    "        self.conv128blocks = nn.Sequential(\n",
    "            self.BlockClass(64, 128, Downsample_option=\"C\"),\n",
    "            self.BlockClass(128, 128),\n",
    "            self.BlockClass(128, 128),\n",
    "            self.BlockClass(128, 128),\n",
    "        )\n",
    "        self.conv256blocks = nn.Sequential(\n",
    "            self.BlockClass(128, 256, Downsample_option=\"C\"),\n",
    "            self.BlockClass(256, 256),\n",
    "            self.BlockClass(256, 256),\n",
    "            self.BlockClass(256, 256),\n",
    "            self.BlockClass(256, 256),\n",
    "            self.BlockClass(256, 256),\n",
    "        )\n",
    "        self.conv512blocks = nn.Sequential(\n",
    "            self.BlockClass(256, 512, Downsample_option=\"C\"),\n",
    "            self.BlockClass(512, 512),\n",
    "            self.BlockClass(512, 512),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(in_features=512, out_features=self.num_classes, bias=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv64blocks(x)\n",
    "        x = self.conv128blocks(x)\n",
    "        x = self.conv256blocks(x)\n",
    "        x = self.conv512blocks(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet_CIFAR(nn.Module):\n",
    "    def __init__(self, num_classes, num_layer_factor, BlockClass=Block):\n",
    "        super().__init__()\n",
    "        self.num_layer_factor = num_layer_factor\n",
    "        self.num_classes = num_classes\n",
    "        self.BlockClass = BlockClass\n",
    "\n",
    "        \"\"\"\n",
    "        - The subsampling is preformed by convolutions with a stride 2.\n",
    "        - The network ands with a global average pooling, a 10-way fully-connected layer, and softmax.\n",
    "        - There are totally 6n+2 stacked weighted layers.\n",
    "        - When shortcut connections are used, they are connected to the pair of 3x3 layers (totally 3n shortcuts).\n",
    "        - On this dataset we use ientity shortcuts in all cases (i.e., option A), \n",
    "            so out residual models habe exactly the same depth, width, and number of parameters as the plain counterparts.\n",
    "        \n",
    "        -------------------------------------\n",
    "        input = (32x32x3)\n",
    "        -------------------------------------\n",
    "        output map size | 32x32 | 16x16 | 8x8\n",
    "        -------------------------------------\n",
    "        #layers         |  1+2n |  2n   | 2n\n",
    "        #filters        |   16  |  32   | 64\n",
    "        -------------------------------------\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv32blocks = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, out_channels=16, kernel_size=3, padding=1, bias=False\n",
    "            ),\n",
    "            self.BlockClass(16, 16),\n",
    "        )\n",
    "        self.conv16blocks = nn.Sequential(\n",
    "            self.BlockClass(16, 32, Downsample_option=\"A\"),\n",
    "        )\n",
    "        self.conv8blocks = nn.Sequential(\n",
    "            self.BlockClass(32, 64, Downsample_option=\"A\"),\n",
    "        )\n",
    "\n",
    "        for i in range(1, self.num_layer_factor):\n",
    "            self.conv32blocks.append(self.BlockClass(16, 16))\n",
    "            self.conv16blocks.append(self.BlockClass(32, 32))\n",
    "            self.conv8blocks.append(self.BlockClass(64, 64))\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=(64), out_features=self.num_classes, bias=True\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv32blocks(x)\n",
    "        x = self.conv16blocks(x)\n",
    "        x = self.conv8blocks(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 CPU나 GPU, MPS 장치를 얻습니다.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"CIFAR10\" or DATASET == \"CIFAR100\":\n",
    "    \"\"\"ResNet{20, 32, 44, 56, 110, 1202} for CIFAR\"\"\"\n",
    "    model = MyResNet_CIFAR(num_classes=COUNT_OF_CLASSES, num_layer_factor=5).to(device)\n",
    "    print(f\"ResNet-{5*6+2} for {DATASET} is loaded.\")\n",
    "    \n",
    "elif DATASET == \"ImageNet2012\":\n",
    "    \"\"\"ResNet34 for ImageNet 2012\"\"\"\n",
    "    model = MyResNet34(num_classes=COUNT_OF_CLASSES).to(device)\n",
    "    # model = models.resnet34(pretrained=True).to(device)\n",
    "    # model = models.resnet34(pretrained=False).to(device)\n",
    "    print(f\"ResNet-34 for {DATASET} is loaded.\")\n",
    "    \n",
    "# model.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_input = torch.rand(BATCH, 3, 32, 32).to(device)\n",
    "flops = FlopCountAnalysis(model, tmp_input)\n",
    "print(flop_count_table(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Optimazer\n",
    "#### ResNet32 for CIFAR10\n",
    "- SGD\n",
    "- Batch size = 128 * 2 GPU\n",
    "- lr : 0.1 -> 0.01 -> 0.001 (at 32k, 48k and terminate on 64k iter)\n",
    "  - divided by 10 when the error plateaus\n",
    "- Weight Decay = 0.0001\n",
    "- Momentum = 0.9\n",
    "#### ResNet34 for ImageNet2012\n",
    "- SGD\n",
    "- Batch size = 256\n",
    "- lr = 0.1\n",
    "  - divided by 10 when the error plateaus\n",
    "  - amount 60k iter\n",
    "- Weight Decay = 0.0001\n",
    "- Momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001\n",
    ")\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping 관련 변수 초기화\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 100  # 몇 번까지 기다릴 것인지\n",
    "early_stop_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Learning Rate schedualer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_mapping = {\"CIFAR100\": 300, \"CIFAR10\": 300, \"ImageNet2012\": 30}\n",
    "MIN_LR = 0.0001\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    patience=scheduler_mapping[DATASET],\n",
    "    factor=0.1,\n",
    "    verbose=True,\n",
    "    threshold=1e-4,\n",
    "    min_lr=MIN_LR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Auto Mixed Pricision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_AMP == True:\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "    if LOAD_BEFORE_WEIGHTS == True:\n",
    "        # Read checkpoint as desired, e.g.,\n",
    "        checkpoint = torch.load(\n",
    "            \"models/amp/\" + DATASET, map_location=lambda storage, loc: storage.cuda(device)\n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        scaler.load_state_dict(checkpoint[\"scaler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Training Loop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "\n",
    "\n",
    "_log_train_loss = []\n",
    "_log_train_acc = []\n",
    "_log_valid_loss = []\n",
    "_log_valid_acc = []\n",
    "_log_test_loss = []\n",
    "_log_test_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] :\")\n",
    "\n",
    "    # Training loop @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm.tqdm(train_dataloader):\n",
    "        if USE_AMP == True:\n",
    "            \"\"\"with auto mixed precision\"\"\"\n",
    "            with torch.autocast(\n",
    "                device_type=\"cuda\", dtype=torch.float16, enabled=USE_AMP\n",
    "            ):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        else:\n",
    "            \"\"\"without auto mixed precision\"\"\"\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    _, predicted = outputs.max(1)\n",
    "    total += labels.size(0)\n",
    "    correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Evaluation loop @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    valid_loss /= len(valid_dataloader)\n",
    "    valid_acc = correct / total\n",
    "\n",
    "    if DATASET == \"ImageNet2012\":\n",
    "        pass\n",
    "    else:\n",
    "        # Testing loop @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc = correct / total\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    _log_train_loss.append(train_loss)\n",
    "    _log_train_acc.append(train_acc)\n",
    "\n",
    "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc*100:.2f}%\")\n",
    "    _log_valid_loss.append(valid_loss)\n",
    "    _log_valid_acc.append(valid_acc)\n",
    "\n",
    "    if DATASET == \"ImageNet2012\":\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Test  Loss: {test_loss:.4f} | Test Acc: {test_acc*100:.2f}%\")\n",
    "        _log_test_loss.append(test_loss)\n",
    "        _log_test_acc.append(test_acc)\n",
    "\n",
    "    # Early stopping check\n",
    "    scheduler.step(valid_loss)\n",
    "    if valid_loss < best_val_loss:\n",
    "        best_val_loss = valid_loss\n",
    "        early_stop_counter = 0\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), f\"models/Myresnet34{DATASET}.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping after {epoch} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "# 저장할 파일 경로 지정\n",
    "current_time = datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "output_file_path = f\"log/{DATASET}/train_log_{formatted_time}.txt\"\n",
    "\n",
    "# 캡처한 출력을 파일로 저장\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    f.write(captured_output.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_AMP == True:\n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scaler\": scaler.state_dict(),\n",
    "    }\n",
    "    # Write checkpoint as desired, e.g.,\n",
    "    torch.save(checkpoint, \"models/amp/\" + DATASET)\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/Myresnet34{DATASET}.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "# 첫 번째 그래프: Training and Test Loss\n",
    "axs[0].plot(_log_train_loss, label=\"Training Loss\")\n",
    "axs[0].plot(_log_valid_loss, label=\"Validation Loss\")\n",
    "axs[0].plot(_log_test_loss, label=\"Test Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_title(\"Training, Validation and Test Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# 두 번째 그래프: Training and Test Accuracy\n",
    "axs[1].plot(_log_train_acc , label=\"Training Accuracy\")\n",
    "axs[1].plot(_log_valid_acc , label=\"Validation Accuracy\")\n",
    "axs[1].plot(_log_test_acc, label=\"Test Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].set_title(\"Training, Validation and Test Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "# 그래프를 보여줍니다.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "_log_test_acc[-1] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"ImageNet2012\":\n",
    "    model = MyResNet34(num_classes=COUNT_OF_CLASSES).to(device)\n",
    "else:\n",
    "    model = MyResNet_CIFAR(num_classes=COUNT_OF_CLASSES, num_layer_factor=5).to(device)\n",
    "model.load_state_dict(torch.load(f\"models/Myresnet34{DATASET}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
